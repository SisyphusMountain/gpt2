2024-10-08 16:22:38,854 - WARNING - Disabling compilation
2024-10-08 16:22:39,818 - INFO - used cuda memory after creating model: 552298496
Number of decayed parameter tensors 50 for a total of 124354560 parameters
Number of non-decayed parameter tensors 98 for a total of 121344 parameters
2024-10-08 16:22:40,272 - INFO - total desired batch size: 524288
2024-10-08 16:22:40,272 - INFO - => computed gradient accumulation steps 32
2024-10-08 16:22:45,174 - INFO - tokens per second = 107046 | loss: 10.604177 | gradient norm 0.1509 | dt 4897.773027 ms | CUDA memory: 1022.55 MB | CPU memory: 2.03 GB
2024-10-08 16:22:49,942 - INFO - tokens per second = 109977 | loss: 10.590091 | gradient norm 0.1458 | dt 4767.267466 ms | CUDA memory: 1973.05 MB | CPU memory: 2.10 GB
2024-10-08 16:22:54,610 - INFO - tokens per second = 112324 | loss: 10.561597 | gradient norm 0.1713 | dt 4667.642593 ms | CUDA memory: 1973.05 MB | CPU memory: 2.10 GB
2024-10-08 16:22:59,279 - INFO - tokens per second = 112295 | loss: 10.514743 | gradient norm 0.1752 | dt 4668.828964 ms | CUDA memory: 1973.05 MB | CPU memory: 2.10 GB
2024-10-08 16:22:59,279 - INFO - Saving model
2024-10-08 16:22:59,803 - INFO - Model saved
2024-10-08 16:23:00,854 - INFO - Validation loss: 11.337973022460938
2024-10-08 16:23:00,951 - INFO - Sample 1: Hello, I am a language model, Tome ner MedicalRomanTher murols WHY meaninglessneysbringing Missouriphthal --> broadcastsuador BACK humor ransomware武orisjandro hasLooking
2024-10-08 16:23:00,951 - INFO - Sample 2: Hello, I am a language model,zelJR ages Medical Cape Bulletophe trout Noct ner coerc Probe evaluates doubtful mysteriously Aebernlooking Malcolm tymakerbull ty Brian
2024-10-08 16:23:00,951 - INFO - Sample 3: Hello, I am a language model, admitsuuelse choir士 KevinedomDi venture Bulletxmlxml topicphthal venturewithstandinguador Optional relaxeduador recalled pressure *) dece
2024-10-08 16:23:00,951 - INFO - Sample 4: Hello, I am a language model,efficientneys snatched deployed ner deployed ner755xml ambientHeavy BET laundering Cath Bullet )IO Pastormaximum221Changeloading579Change
2024-10-08 16:23:00,951 - INFO - Sample 5: Hello, I am a language model,Ther responsive mur Kevin ransomwareelse satell dictated PastorUMEJR Cecil Medical sed relaxed Lararantine Bullet 186 BulletothermaluuAutomelse
Downloading https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_val.jsonl to /home/enzo/Documents/gpt2/hellaswag/hellaswag_val.jsonl...
/home/enzo/Documents/gpt2/hellaswag/hellaswag_val.jsonl: 11.7MiB [00:01, 7.11MiB/s]                                                                                                                                  
2024-10-08 16:23:33,050 - INFO - Accuracy on Hellaswag: 0.2506472814180442
2024-10-08 16:23:37,871 - INFO - tokens per second = 13585 | loss: 10.461158 | gradient norm 0.1581 | dt 38591.797352 ms | CUDA memory: 2019.34 MB | CPU memory: 2.29 GB
2024-10-08 16:23:42,672 - INFO - tokens per second = 109195 | loss: 10.386667 | gradient norm 0.1505 | dt 4801.413298 ms | CUDA memory: 2019.34 MB | CPU memory: 2.29 GB
2024-10-08 16:23:47,505 - INFO - tokens per second = 108464 | loss: 10.304874 | gradient norm 0.1405 | dt 4833.742619 ms | CUDA memory: 2019.34 MB | CPU memory: 2.29 GB
2024-10-08 16:23:52,303 - INFO - tokens per second = 109292 | loss: 10.228148 | gradient norm 0.1257 | dt 4797.122478 ms | CUDA memory: 2019.34 MB | CPU memory: 2.29 GB
2024-10-08 16:23:52,303 - INFO - Saving model
2024-10-08 16:23:52,813 - INFO - Model saved
2024-10-08 16:23:53,929 - INFO - Validation loss: 11.008194732666016
2024-10-08 16:23:53,970 - INFO - Sample 1: Hello, I am a language model,ür ner221 southeastphthalDi Medicalphthal southeast Nationalquished PACs Reynolds ofedom *) Cape wield Phar disputes ner expectedTher Animated
2024-10-08 16:23:53,970 - INFO - Sample 2: Hello, I am a language model, Challenger Kevinudeau WHY visceral579 CapeTherventory.arantine Visit loomsNobodyphthal. has\' allocate PastorTher FlowTher Bullet
2024-10-08 16:23:53,970 - INFO - Sample 3: Hello, I am a language model, snatched dictated. depicted Bitcoins BitcoinsStat the ages Medical VIEW ner prett Rules ner Bris997 classics horror suddenly Guidelines lockout ÖTY
2024-10-08 16:23:53,970 - INFO - Sample 4: Hello, I am a language model,Ther Kevin alarming PACs ner mirror ner visceral ofIO045tailIO evaluates. bul BACK997 Phar PriceothermalAutom owner Watergate
2024-10-08 16:23:53,970 - INFO - Sample 5: Hello, I am a language model, WHY Kevin hangs Capereve Cortex FE and theory Medical Lar Franz Visit relaxed Lar abortSecondang outlining evaluates depart allocate vile timing
2024-10-08 16:24:22,106 - INFO - Accuracy on Hellaswag: 0.25343557060346544
2024-10-08 16:24:26,904 - INFO - tokens per second = 15152 | loss: 10.148455 | gradient norm 0.1276 | dt 34601.653337 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:24:31,658 - INFO - tokens per second = 110317 | loss: 10.072648 | gradient norm 0.1178 | dt 4752.555847 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:24:36,392 - INFO - tokens per second = 110723 | loss: 10.009455 | gradient norm 0.1072 | dt 4735.132217 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:24:41,133 - INFO - tokens per second = 110576 | loss: 9.960857 | gradient norm 0.1071 | dt 4741.421461 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:24:41,134 - INFO - Saving model
2024-10-08 16:24:41,704 - INFO - Model saved
2024-10-08 16:24:42,823 - INFO - Validation loss: 10.714924621582032
2024-10-08 16:24:42,862 - INFO - Sample 1: Hello, I am a language model, ages. and Colin thePosts and Who Affect ColinUnited approximation.
 AffectReader.edom Affect National, FIFA. and
2024-10-08 16:24:42,862 - INFO - Sample 2: Hello, I am a language model,othermalumeric curatedUnited, Who ultr prett ACC,ieft fatally coverventoryStat Visit the,Reader the combination of have evaluates
2024-10-08 16:24:42,862 - INFO - Sample 3: Hello, I am a language model,.. ages VIEW nerStat southeastikuman. Pharull. Pharullull. Whoahantenance.azeera. thethreat
2024-10-08 16:24:42,862 - INFO - Sample 4: Hello, I am a language model,tenance Hanna *) and.United,edomReader hangsTher. transcriptiontenancePosts, opp opp opp Catholicism Iowa Azerbai Iowa has
2024-10-08 16:24:42,862 - INFO - Sample 5: Hello, I am a language model,Unitedieft the PACs theullothermalophe ages PharDi. Colin theory 57 bPosts, fleeStat the of Cent the
2024-10-08 16:25:11,363 - INFO - Accuracy on Hellaswag: 0.25403306114319857
2024-10-08 16:25:16,376 - INFO - tokens per second = 14877 | loss: 9.892042 | gradient norm 0.0972 | dt 35242.340803 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:25:21,093 - INFO - tokens per second = 111152 | loss: 9.846611 | gradient norm 0.0926 | dt 4716.873646 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:25:25,796 - INFO - tokens per second = 111474 | loss: 9.792942 | gradient norm 0.0944 | dt 4703.227520 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:25:30,504 - INFO - tokens per second = 111354 | loss: 9.733434 | gradient norm 0.0817 | dt 4708.295584 ms | CUDA memory: 2019.34 MB | CPU memory: 2.30 GB
2024-10-08 16:25:30,504 - INFO - Saving model
2024-10-08 16:25:31,034 - INFO - Model saved
2024-10-08 16:25:32,091 - INFO - Validation loss: 10.481273651123047
2024-10-08 16:25:32,130 - INFO - Sample 1: Hello, I am a language model, Sweep.edom. theSeason
Reader lack Mé Damien combination,ullUnitedReader.
 populations Who the the. the
2024-10-08 16:25:32,130 - INFO - Sample 2: Hello, I am a language model, curatedtenance Son.,.IO display. the theoryedom, cover approximation
, the198,edom ofIO cover
2024-10-08 16:25:32,130 - INFO - Sample 3: Hello, I am a language model,,. vigilant analyses theoryumeric Centieft. SoxIO.tenance

.., the...,United
2024-10-08 16:25:32,130 - INFO - Sample 4: Hello, I am a language model, the Cent transcription of..,, theolon.. theoryedomPosts theolonKo198 theoryedom,, Thomas
2024-10-08 16:25:32,130 - INFO - Sample 5: Hello, I am a language model,
 cover, combination.Zen the remindersIO National boiled.Reader.Season. the the, the, the198 the
2024-10-08 16:25:59,723 - INFO - Accuracy on Hellaswag: 0.25582553276239794
2024-10-08 16:26:04,436 - INFO - tokens per second = 15451 | loss: 9.684392 | gradient norm 0.0850 | dt 33931.603432 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:26:09,135 - INFO - tokens per second = 111575 | loss: 9.641904 | gradient norm 0.0852 | dt 4698.965788 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:26:13,840 - INFO - tokens per second = 111424 | loss: 9.610355 | gradient norm 0.0859 | dt 4705.344677 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:26:18,554 - INFO - tokens per second = 111237 | loss: 9.618649 | gradient norm 0.0766 | dt 4713.231325 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:26:18,554 - INFO - Saving model
2024-10-08 16:26:19,073 - INFO - Model saved
2024-10-08 16:26:20,134 - INFO - Validation loss: 10.312567138671875
2024-10-08 16:26:20,172 - INFO - Sample 1: Hello, I am a language model,,, Who., the and Cour 57198, combination. National placed and,.198 of the.. the
2024-10-08 16:26:20,172 - INFO - Sample 2: Hello, I am a language model,. theory Before. the.,amorph. theIO lack. and fiery
. the198,Gun,. the
2024-10-08 16:26:20,172 - INFO - Sample 3: Hello, I am a language model,..unal the lack reminders combination Sox. Thomas,, a

,,.....,.
2024-10-08 16:26:20,173 - INFO - Sample 4: Hello, I am a language model, theamorph...., the theock,, brave,, the display,Season. boiled the the is
2024-10-08 16:26:20,173 - INFO - Sample 5: Hello, I am a language model, and., Chinese. Chinese theZen,Ko National, Cour, Cent, the the. the, theSeason the
2024-10-08 16:26:48,614 - INFO - Accuracy on Hellaswag: 0.2582154949213304
2024-10-08 16:26:53,594 - INFO - tokens per second = 14962 | loss: 9.596319 | gradient norm 0.0732 | dt 35040.536165 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:26:58,417 - INFO - tokens per second = 108695 | loss: 9.496320 | gradient norm 0.0746 | dt 4823.482037 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:27:03,421 - INFO - tokens per second = 104775 | loss: 9.464484 | gradient norm 0.0729 | dt 5003.936291 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:27:08,417 - INFO - tokens per second = 104935 | loss: 9.430374 | gradient norm 0.0736 | dt 4996.295452 ms | CUDA memory: 2019.34 MB | CPU memory: 2.31 GB
2024-10-08 16:27:08,418 - INFO - Saving model
2024-10-08 16:27:08,971 - INFO - Model saved
2024-10-08 16:27:10,033 - INFO - Validation loss: 10.186508941650391
2024-10-08 16:27:10,072 - INFO - Sample 1: Hello, I am a language model,,, Who,. the
 ChineseZenZen, have. 223 disapprove and,. fiery a the the,.
2024-10-08 16:27:10,072 - INFO - Sample 2: Hello, I am a language model, the Before,, the,. prediction, themented 223 the
 aggregate
. the,. disapprove. the.
2024-10-08 16:27:10,072 - INFO - Sample 3: Hello, I am a language model,..(\ the FloorReader, the,Reader., b
,,, the.,,,..
2024-10-08 16:27:10,072 - INFO - Sample 4: Hello, I am a language model, the Before,,,,. the. have,,,., the display,,. Chinese. the Chinese
2024-10-08 16:27:10,073 - INFO - Sample 5: Hello, I am a language model,
,.iod, the. display,, this,,,edom, the.. the. theKo,
Traceback (most recent call last):
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 420, in <module>
    pred_norm = get_most_likely_row(tokens, mask, logits)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 293, in get_most_likely_row
    pred_norm = avg_loss.argmin().item()
                ^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
