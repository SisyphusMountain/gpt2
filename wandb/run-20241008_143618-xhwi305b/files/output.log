2024-10-08 14:36:19,117 - WARNING - Disabling compilation
2024-10-08 14:36:20,078 - INFO - used cuda memory after creating model: 552298496
Number of decayed parameter tensors 50 for a total of 124354560 parameters
Number of non-decayed parameter tensors 98 for a total of 121344 parameters
2024-10-08 14:36:20,666 - INFO - total desired batch size: 524288
2024-10-08 14:36:20,666 - INFO - => computed gradient accumulation steps 32
2024-10-08 14:36:25,631 - INFO - tokens per second = 105696 | loss: 10.641262 | gradient norm 0.1766 | dt 4960.328579 ms | CUDA memory: 1022.55 MB | CPU memory: 1.95 GB
2024-10-08 14:36:30,917 - INFO - tokens per second = 99189 | loss: 10.623198 | gradient norm 0.1655 | dt 5285.773277 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:36:35,619 - INFO - tokens per second = 111513 | loss: 10.581820 | gradient norm 0.1898 | dt 4701.577187 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:36:40,642 - INFO - tokens per second = 104381 | loss: 10.534668 | gradient norm 0.1979 | dt 5022.823095 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:36:45,779 - INFO - tokens per second = 102055 | loss: 10.463367 | gradient norm 0.1747 | dt 5137.297392 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:36:50,684 - INFO - tokens per second = 106880 | loss: 10.384579 | gradient norm 0.1610 | dt 4905.387163 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:36:55,794 - INFO - tokens per second = 102597 | loss: 10.303055 | gradient norm 0.1548 | dt 5110.145807 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:00,893 - INFO - tokens per second = 102833 | loss: 10.207381 | gradient norm 0.1365 | dt 5098.456860 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:05,791 - INFO - tokens per second = 107039 | loss: 10.124004 | gradient norm 0.1411 | dt 4898.112059 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:10,673 - INFO - tokens per second = 107390 | loss: 10.038251 | gradient norm 0.1270 | dt 4882.099867 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:15,530 - INFO - tokens per second = 107940 | loss: 9.962107 | gradient norm 0.1129 | dt 4857.195854 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:20,453 - INFO - tokens per second = 106508 | loss: 9.904572 | gradient norm 0.1130 | dt 4922.508001 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:25,365 - INFO - tokens per second = 106721 | loss: 9.828541 | gradient norm 0.1020 | dt 4912.681103 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:30,330 - INFO - tokens per second = 105606 | loss: 9.786934 | gradient norm 0.0933 | dt 4964.572668 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:35,329 - INFO - tokens per second = 104871 | loss: 9.722732 | gradient norm 0.0967 | dt 4999.357939 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:40,123 - INFO - tokens per second = 109369 | loss: 9.662026 | gradient norm 0.0832 | dt 4793.750286 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:45,021 - INFO - tokens per second = 107034 | loss: 9.615213 | gradient norm 0.0863 | dt 4898.334503 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:49,814 - INFO - tokens per second = 109389 | loss: 9.569388 | gradient norm 0.0857 | dt 4792.881250 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:54,606 - INFO - tokens per second = 109406 | loss: 9.531837 | gradient norm 0.0836 | dt 4792.140007 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:37:59,406 - INFO - tokens per second = 109225 | loss: 9.555607 | gradient norm 0.0754 | dt 4800.071955 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:38:04,538 - INFO - tokens per second = 102167 | loss: 9.530411 | gradient norm 0.0717 | dt 5131.657124 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:38:09,531 - INFO - tokens per second = 105015 | loss: 9.426003 | gradient norm 0.0730 | dt 4992.514849 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:38:14,631 - INFO - tokens per second = 102785 | loss: 9.390037 | gradient norm 0.0710 | dt 5100.831270 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
2024-10-08 14:38:19,704 - INFO - tokens per second = 103364 | loss: 9.355403 | gradient norm 0.0711 | dt 5072.262526 ms | CUDA memory: 1973.05 MB | CPU memory: 2.02 GB
Traceback (most recent call last):
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 293, in <module>
    loss, norm = training_step(x, y)
                 ^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 264, in training_step
    norm = torch.nn.utils.clip_grad_norm_(model.parameters(),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 21, in _no_grad_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 82, in clip_grad_norm_
    clip_coef = max_norm / (total_norm + 1e-6)
                ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/_tensor.py", line 35, in wrapped
    @functools.wraps(f, assigned=assigned)

KeyboardInterrupt
