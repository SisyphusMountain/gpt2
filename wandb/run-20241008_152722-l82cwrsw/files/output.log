2024-10-08 15:27:23,084 - WARNING - Disabling compilation
2024-10-08 15:27:24,038 - INFO - used cuda memory after creating model: 552298496
Number of decayed parameter tensors 50 for a total of 124354560 parameters
Number of non-decayed parameter tensors 98 for a total of 121344 parameters
2024-10-08 15:27:24,616 - INFO - total desired batch size: 524288
2024-10-08 15:27:24,616 - INFO - => computed gradient accumulation steps 32
2024-10-08 15:27:29,536 - INFO - tokens per second = 106642 | loss: 10.643585 | gradient norm 0.1577 | dt 4916.340590 ms | CUDA memory: 1022.55 MB | CPU memory: 1.99 GB
2024-10-08 15:27:34,373 - INFO - tokens per second = 108405 | loss: 10.626966 | gradient norm 0.1528 | dt 4836.381435 ms | CUDA memory: 1973.05 MB | CPU memory: 2.06 GB
2024-10-08 15:27:39,060 - INFO - tokens per second = 111870 | loss: 10.599575 | gradient norm 0.1672 | dt 4686.572552 ms | CUDA memory: 1973.05 MB | CPU memory: 2.06 GB
2024-10-08 15:27:43,752 - INFO - tokens per second = 111729 | loss: 10.551091 | gradient norm 0.1779 | dt 4692.515612 ms | CUDA memory: 1973.05 MB | CPU memory: 2.06 GB
2024-10-08 15:27:43,753 - INFO - Saving model
2024-10-08 15:27:44,294 - INFO - Model saved
2024-10-08 15:27:45,346 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:27:46,716 - INFO - Saving model
2024-10-08 15:27:47,257 - INFO - Model saved
2024-10-08 15:27:48,312 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:27:48,894 - INFO - Saving model
2024-10-08 15:27:49,414 - INFO - Model saved
2024-10-08 15:27:50,473 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:27:51,277 - INFO - Saving model
2024-10-08 15:27:51,776 - INFO - Model saved
2024-10-08 15:27:52,830 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:27:53,516 - INFO - Saving model
2024-10-08 15:27:54,015 - INFO - Model saved
2024-10-08 15:27:55,073 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:00,903 - INFO - Saving model
2024-10-08 15:28:01,436 - INFO - Model saved
2024-10-08 15:28:02,490 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:03,449 - INFO - Saving model
2024-10-08 15:28:03,942 - INFO - Model saved
2024-10-08 15:28:05,000 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:05,907 - INFO - Saving model
2024-10-08 15:28:06,417 - INFO - Model saved
2024-10-08 15:28:07,478 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:08,161 - INFO - Saving model
2024-10-08 15:28:08,661 - INFO - Model saved
2024-10-08 15:28:09,731 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:10,252 - INFO - Saving model
2024-10-08 15:28:10,834 - INFO - Model saved
2024-10-08 15:28:11,923 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:12,568 - INFO - Saving model
2024-10-08 15:28:13,068 - INFO - Model saved
2024-10-08 15:28:14,133 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:14,716 - INFO - Saving model
2024-10-08 15:28:15,210 - INFO - Model saved
2024-10-08 15:28:16,270 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:16,866 - INFO - Saving model
2024-10-08 15:28:17,369 - INFO - Model saved
2024-10-08 15:28:18,425 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:19,224 - INFO - Saving model
2024-10-08 15:28:19,783 - INFO - Model saved
2024-10-08 15:28:20,842 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:21,580 - INFO - Saving model
2024-10-08 15:28:22,080 - INFO - Model saved
2024-10-08 15:28:23,157 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:23,747 - INFO - Saving model
2024-10-08 15:28:24,248 - INFO - Model saved
2024-10-08 15:28:25,326 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:26,185 - INFO - Saving model
2024-10-08 15:28:26,676 - INFO - Model saved
2024-10-08 15:28:27,741 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:28,646 - INFO - Saving model
2024-10-08 15:28:29,202 - INFO - Model saved
2024-10-08 15:28:30,325 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:31,105 - INFO - Saving model
2024-10-08 15:28:31,601 - INFO - Model saved
2024-10-08 15:28:32,658 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:33,257 - INFO - Saving model
2024-10-08 15:28:33,766 - INFO - Model saved
2024-10-08 15:28:34,847 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:35,350 - INFO - Saving model
2024-10-08 15:28:35,856 - INFO - Model saved
2024-10-08 15:28:36,947 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:37,661 - INFO - Saving model
2024-10-08 15:28:38,191 - INFO - Model saved
2024-10-08 15:28:39,269 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:39,904 - INFO - Saving model
2024-10-08 15:28:40,405 - INFO - Model saved
2024-10-08 15:28:41,466 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:42,101 - INFO - Saving model
2024-10-08 15:28:42,599 - INFO - Model saved
2024-10-08 15:28:43,659 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:44,325 - INFO - Saving model
2024-10-08 15:28:44,847 - INFO - Model saved
2024-10-08 15:28:45,909 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:46,675 - INFO - Saving model
2024-10-08 15:28:47,203 - INFO - Model saved
2024-10-08 15:28:48,269 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:48,823 - INFO - Saving model
2024-10-08 15:28:49,367 - INFO - Model saved
2024-10-08 15:28:50,424 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:51,292 - INFO - Saving model
2024-10-08 15:28:51,785 - INFO - Model saved
2024-10-08 15:28:52,969 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:53,669 - INFO - Saving model
2024-10-08 15:28:54,191 - INFO - Model saved
2024-10-08 15:28:55,262 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:55,894 - INFO - Saving model
2024-10-08 15:28:56,414 - INFO - Model saved
2024-10-08 15:28:57,482 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:28:58,451 - INFO - Saving model
2024-10-08 15:28:58,935 - INFO - Model saved
2024-10-08 15:29:00,004 - INFO - Validation loss: 11.377214050292968
2024-10-08 15:29:00,720 - INFO - tokens per second = 6812 | loss: 10.489789 | gradient norm 0.1632 | dt 76967.676401 ms | CUDA memory: 1978.24 MB | CPU memory: 2.26 GB
2024-10-08 15:29:05,530 - INFO - tokens per second = 109005 | loss: 10.412365 | gradient norm 0.1522 | dt 4809.770346 ms | CUDA memory: 1978.24 MB | CPU memory: 2.26 GB
Traceback (most recent call last):
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 294, in <module>
    loss, norm = training_step(x, y)
                 ^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 265, in training_step
    norm = torch.nn.utils.clip_grad_norm_(model.parameters(),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 21, in _no_grad_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 82, in clip_grad_norm_
    clip_coef = max_norm / (total_norm + 1e-6)
                ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/_tensor.py", line 35, in wrapped
    @functools.wraps(f, assigned=assigned)

KeyboardInterrupt
