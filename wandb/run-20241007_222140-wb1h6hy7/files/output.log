2024-10-07 22:21:40,650 - INFO - Enabling compilation
2024-10-07 22:21:41,958 - INFO - used cuda memory after creating model: 552298496
Number of decayed parameter tensors 50 for a total of 124354560 parameters
Number of non-decayed parameter tensors 98 for a total of 121344 parameters
2024-10-07 22:21:42,773 - INFO - total desired batch size: 524288
2024-10-07 22:21:42,773 - INFO - => computed gradient accumulation steps 32
2024-10-07 22:21:42,774 - INFO - Starting epoch 0
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/wandb/sdk/lib/exit_hooks.py", line 41, in exc_handler
    def exc_handler(

KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 303, in <module>
    loss, norm = training_step(x, y)
                 ^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 433, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 266, in training_step
    @torch.compile(mode="max-autotune", disable=disable_compilation)
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 268, in torch_dynamo_resume_in_training_step_at_268
    optimizer.zero_grad()
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
