2024-10-08 15:45:21,452 - WARNING - Disabling compilation
2024-10-08 15:45:22,422 - INFO - used cuda memory after creating model: 552298496
Number of decayed parameter tensors 50 for a total of 124354560 parameters
Number of non-decayed parameter tensors 98 for a total of 121344 parameters
2024-10-08 15:45:22,998 - INFO - total desired batch size: 524288
2024-10-08 15:45:22,998 - INFO - => computed gradient accumulation steps 32
2024-10-08 15:45:27,970 - INFO - tokens per second = 105536 | loss: 10.720598 | gradient norm 0.1631 | dt 4967.862606 ms | CUDA memory: 1022.55 MB | CPU memory: 1.98 GB
2024-10-08 15:45:33,047 - INFO - tokens per second = 103280 | loss: 10.702413 | gradient norm 0.1515 | dt 5076.365471 ms | CUDA memory: 1973.05 MB | CPU memory: 2.05 GB
2024-10-08 15:45:38,159 - INFO - tokens per second = 102565 | loss: 10.672620 | gradient norm 0.1695 | dt 5111.782312 ms | CUDA memory: 1973.05 MB | CPU memory: 2.05 GB
2024-10-08 15:45:42,961 - INFO - tokens per second = 109180 | loss: 10.621809 | gradient norm 0.1791 | dt 4802.068233 ms | CUDA memory: 1973.05 MB | CPU memory: 2.05 GB
2024-10-08 15:45:42,961 - INFO - Saving model
2024-10-08 15:45:43,484 - INFO - Model saved
2024-10-08 15:45:44,563 - INFO - Validation loss: 11.442925262451173
2024-10-08 15:45:44,660 - INFO - Sample 1: Hello, I am a language model, Sop artificially Coin NHffitiizzyarge kickoff attacks empt Deploy Definition valve upcoming="# kickoff explanmmmm PHPCHR real flood floodiliation
2024-10-08 15:45:44,661 - INFO - Sample 2: Hello, I am a language model, 10 bumped real members Mages aspectizzyfeeding controversialapacyl platinum Thybably membersrovers#$#$DR bumpedDR platinumava paramedics Parliamentary
2024-10-08 15:45:44,661 - INFO - Sample 3: Hello, I am a language model,JS disbanded twentyInvalid Imperial Were coping Beau checkout Tokens CatchInvalid artificiallyInvalidmarketstxisiteoras posedale slug realmarkets real
2024-10-08 15:45:44,661 - INFO - Sample 4: Hello, I am a language model,pter platinum kickoffpterffiti empt empt covertrimp massesbably branch protestingmmmm signaled shootoutizzy Fearffiti messy disbandedpterRegarding cens
2024-10-08 15:45:44,661 - INFO - Sample 5: Hello, I am a language model,markets Kenobifeeding Beau shatter Were shun Places shunrimp reelection mobility real platinum Remastered330CHRcylI="#cyl Tribalotechnology vaginal
2024-10-08 15:45:50,608 - INFO - tokens per second = 68560 | loss: 10.556482 | gradient norm 0.1697 | dt 7647.087812 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:45:55,647 - INFO - tokens per second = 104048 | loss: 10.477006 | gradient norm 0.1620 | dt 5038.927317 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:46:00,421 - INFO - tokens per second = 109823 | loss: 10.393623 | gradient norm 0.1485 | dt 4773.931265 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:46:05,325 - INFO - tokens per second = 106914 | loss: 10.304543 | gradient norm 0.1343 | dt 4903.813124 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:46:05,325 - INFO - Saving model
2024-10-08 15:46:05,819 - INFO - Model saved
2024-10-08 15:46:06,909 - INFO - Validation loss: 11.067742156982423
2024-10-08 15:46:06,950 - INFO - Sample 1: Hello, I am a language model,ancock casinoickyfeedingconsumingoisefeeding predictableickyicky controversial Fear epid viable teasp670 coarse taxis alike EdisonCHR Victory the Renaissance
2024-10-08 15:46:06,951 - INFO - Sample 2: Hello, I am a language model,ophile flood bats artificially artificially benefits Def avoidanceophile loser330 Thy morally Paste destabilCHR Def670 real create670 1933bably Paste
2024-10-08 15:46:06,951 - INFO - Sample 3: Hello, I am a language model, bumped multiplication CH liberalism breezeagents Ak signifyires129izzyCHR heating platinumapa today brancholid Prairie benefits enhanced flagshipmmmm create
2024-10-08 15:46:06,951 - INFO - Sample 4: Hello, I am a language model,apa smartphone viable Coin Coinormalapapter 321agraph BoiseaminerCHR create
129きBIL bumped JS advisor ironic Prairie Edison
2024-10-08 15:46:06,951 - INFO - Sample 5: Hello, I am a language model,pter bats CitadelBIL viable archived bandwidth Trahour bandwidth cognitive sulfur Mages alike branchHTML Neander kickoff bodilyshapeshifter protesting nearly402 kickoff
2024-10-08 15:46:12,236 - INFO - tokens per second = 75860 | loss: 10.213560 | gradient norm 0.1377 | dt 6911.252737 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:17,032 - INFO - tokens per second = 109320 | loss: 10.124191 | gradient norm 0.1252 | dt 4795.914888 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:21,984 - INFO - tokens per second = 105870 | loss: 10.042091 | gradient norm 0.1110 | dt 4952.191114 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:26,808 - INFO - tokens per second = 108678 | loss: 9.982978 | gradient norm 0.1117 | dt 4824.240208 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:26,808 - INFO - Saving model
2024-10-08 15:46:27,324 - INFO - Model saved
2024-10-08 15:46:28,385 - INFO - Validation loss: 10.730436706542969
2024-10-08 15:46:28,426 - INFO - Sample 1: Hello, I am a language model,anza. multiplication670.ulation
 Mareapa Literaryamiliar Missile the Coin certificates Coināheng complicit Pack. taxis, Coin
2024-10-08 15:46:28,426 - INFO - Sample 2: Hello, I am a language model, andBIL sulfurkj
 mud transferredprojectsotaur theets Abbynob yuan foreseeable foreseeable the
iago,ancock. impatalling
2024-10-08 15:46:28,426 - INFO - Sample 3: Hello, I am a language model, Algeriaamiliar Works charming Missile signify 344 1933 Wereiece Paste.ā of of, and Mach Mare the Aram, the Works
2024-10-08 15:46:28,426 - INFO - Sample 4: Hello, I am a language model,ickyulation indisp
. foreseeable. Marefty sulfur computer of hood clip flood spends depart groundwater Exxonagus Exxon CH today Neck
2024-10-08 15:46:28,426 - INFO - Sample 5: Hello, I am a language model,otaurotaur,ulation Boise advising spends multiplication advising unhappy ratified nearly seldom330elsen Mach670.Cath benefits the sealed flood,
2024-10-08 15:46:34,077 - INFO - tokens per second = 72125 | loss: 9.907501 | gradient norm 0.1036 | dt 7269.150496 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:38,898 - INFO - tokens per second = 108750 | loss: 9.858768 | gradient norm 0.0940 | dt 4821.042299 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:43,715 - INFO - tokens per second = 108854 | loss: 9.797916 | gradient norm 0.0960 | dt 4816.448450 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:48,604 - INFO - tokens per second = 107243 | loss: 9.736715 | gradient norm 0.0843 | dt 4888.790369 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:46:48,604 - INFO - Saving model
2024-10-08 15:46:49,127 - INFO - Model saved
2024-10-08 15:46:50,281 - INFO - Validation loss: 10.48255615234375
2024-10-08 15:46:50,320 - INFO - Sample 1: Hello, I am a language model, Debor, Abby,. Abbyā unhappy struct taxis se Suz. 110 ratified and,
 clipā theā, and
2024-10-08 15:46:50,321 - INFO - Sample 2: Hello, I am a language model,EGIN MachMaximum, the670eland Blockchain, the se theater the Pack Literary of the.Maximum the unhappy
 struct the
2024-10-08 15:46:50,321 - INFO - Sample 3: Hello, I am a language model,.. Machulation helperulationStyle18, Literary CH, Literary
 of,,..,,,. CBD
2024-10-08 15:46:50,321 - INFO - Sample 4: Hello, I am a language model, Cloグ relaxing
,,. unhappy theirement,,uliffe helper, theighxit theater Literary Ac,.Maximum
2024-10-08 15:46:50,321 - INFO - Sample 5: Hello, I am a language model, and Abby. Literary,Ver sealing Ke 110 If CH, Ke,igh,addon theogenic,. theVer,
2024-10-08 15:46:55,425 - INFO - tokens per second = 76860 | loss: 9.694988 | gradient norm 0.0862 | dt 6821.337223 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:47:00,314 - INFO - tokens per second = 107251 | loss: 9.647240 | gradient norm 0.0875 | dt 4888.420820 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:47:05,194 - INFO - tokens per second = 107436 | loss: 9.605179 | gradient norm 0.0867 | dt 4880.000353 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:47:10,065 - INFO - tokens per second = 107609 | loss: 9.609022 | gradient norm 0.0771 | dt 4872.168303 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:47:10,066 - INFO - Saving model
2024-10-08 15:47:10,576 - INFO - Model saved
2024-10-08 15:47:11,666 - INFO - Validation loss: 10.296372222900391
2024-10-08 15:47:11,704 - INFO - Sample 1: Hello, I am a language model,,,EGIN,., andxitStatistics helper, IM. helperStatistics and,
imity a the., the
2024-10-08 15:47:11,705 - INFO - Sample 2: Hello, I am a language model, listeningulation foreseeable, the,.forth, the inā. and theater
. the,. criticised of,,
2024-10-08 15:47:11,705 - INFO - Sample 3: Hello, I am a language model,.,xit theDesign criticised,projects, If,, Ke
,,, the.,,,..
2024-10-08 15:47:11,705 - INFO - Sample 4: Hello, I am a language model,,projects,,,,. the the biod,,,,, thehes,Design.Ver, the Do
2024-10-08 15:47:11,705 - INFO - Sample 5: Hello, I am a language model, and,. If,, the relaxing,, Missile,,, biod, the..,. the Do,
2024-10-08 15:47:21,941 - INFO - tokens per second = 44149 | loss: 9.592448 | gradient norm 0.0724 | dt 11875.504017 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:26,669 - INFO - tokens per second = 110879 | loss: 9.482386 | gradient norm 0.0749 | dt 4728.459120 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:31,630 - INFO - tokens per second = 105690 | loss: 9.443558 | gradient norm 0.0723 | dt 4960.632324 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:36,378 - INFO - tokens per second = 110427 | loss: 9.409966 | gradient norm 0.0726 | dt 4747.829199 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:36,378 - INFO - Saving model
2024-10-08 15:47:36,908 - INFO - Model saved
2024-10-08 15:47:37,971 - INFO - Validation loss: 10.163436126708984
2024-10-08 15:47:38,010 - INFO - Sample 1: Hello, I am a language model,,,EGIN,. the
 ( never dossier, the the relaxing),
, the the to. the,.
2024-10-08 15:47:38,010 - INFO - Sample 2: Hello, I am a language model, theimated,,., the Canaan,.imityimated the
 vehicle and the., the theater the,.
2024-10-08 15:47:38,010 - INFO - Sample 3: Hello, I am a language model, the, vehicle. Works unhappy,., ( the, Ke and,,, the.,,, the the
2024-10-08 15:47:38,011 - INFO - Sample 4: Hello, I am a language model,.Design,,,,. the. benefits,,,,,. benefits,, the theater.. If
2024-10-08 15:47:38,011 - INFO - Sample 5: Hello, I am a language model,
, the (,,. relaxing,,Len,,, helper,.. the. the.xit,
2024-10-08 15:47:43,540 - INFO - tokens per second = 73196 | loss: 9.407165 | gradient norm 0.0733 | dt 7162.757158 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:48,524 - INFO - tokens per second = 105217 | loss: 9.349984 | gradient norm 0.0732 | dt 4982.943535 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:53,375 - INFO - tokens per second = 108058 | loss: 9.345843 | gradient norm 0.0722 | dt 4851.895809 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:58,366 - INFO - tokens per second = 105045 | loss: 9.317714 | gradient norm 0.0677 | dt 4991.092205 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:47:58,367 - INFO - Saving model
2024-10-08 15:47:58,890 - INFO - Model saved
2024-10-08 15:47:59,960 - INFO - Validation loss: 10.059597778320313
2024-10-08 15:47:59,999 - INFO - Sample 1: Hello, I am a language model,,,EGIN,. the
 (Statistics),,.. is biod
, and the a the the, the
2024-10-08 15:48:00,000 - INFO - Sample 2: Hello, I am a language model,. If,, the,. if, the cooler is. and the and the., theimated the. the
2024-10-08 15:48:00,000 - INFO - Sample 3: Hello, I am a language model, the, Nielsen theDesignaddon. the, ( the the that and and,,..,,, the,
2024-10-08 15:48:00,000 - INFO - Sample 4: Hello, I am a language model,. If,,,,. the theLen,, the the,. scaff to
.), the.projects
2024-10-08 15:48:00,000 - INFO - Sample 5: Hello, I am a language model,
,. (, the theStatistics,,forth,,,imity,. the the.. the is.
2024-10-08 15:48:05,310 - INFO - tokens per second = 75513 | loss: 9.272324 | gradient norm 0.0768 | dt 6943.026781 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:48:10,212 - INFO - tokens per second = 106932 | loss: 9.275808 | gradient norm 0.0704 | dt 4903.016567 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:48:15,174 - INFO - tokens per second = 105692 | loss: 9.238304 | gradient norm 0.0652 | dt 4960.536242 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:48:20,392 - INFO - tokens per second = 100460 | loss: 9.260239 | gradient norm 0.0695 | dt 5218.866110 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:48:20,393 - INFO - Saving model
2024-10-08 15:48:20,903 - INFO - Model saved
2024-10-08 15:48:22,092 - INFO - Validation loss: 9.974167633056641
2024-10-08 15:48:22,133 - INFO - Sample 1: Hello, I am a language model,,, in,. the
,forthforth,.. ( vehicle
, of the and the., the
2024-10-08 15:48:22,133 - INFO - Sample 2: Hello, I am a language model, the never,, the,.xit, the Hilton ( the
 the and the., theimated and,.
2024-10-08 15:48:22,133 - INFO - Sample 3: Hello, I am a language model,., never the hipp;, the, is., that of and,, the.,,,..
2024-10-08 15:48:22,133 - INFO - Sample 4: Hello, I am a language model, the never, of,,. the theimity,,,., theimity a
 the),. the;
2024-10-08 15:48:22,133 - INFO - Sample 5: Hello, I am a language model,
 of the-, the the cooler,, Surrey,,, vehicle,. the the.. the (.
2024-10-08 15:48:27,350 - INFO - tokens per second = 75351 | loss: 9.209568 | gradient norm 0.0685 | dt 6957.935810 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:32,084 - INFO - tokens per second = 110747 | loss: 9.205379 | gradient norm 0.0754 | dt 4734.105349 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:36,860 - INFO - tokens per second = 109782 | loss: 9.175186 | gradient norm 0.0671 | dt 4775.702477 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:41,690 - INFO - tokens per second = 108549 | loss: 9.102335 | gradient norm 0.0687 | dt 4829.953909 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:41,690 - INFO - Saving model
2024-10-08 15:48:42,241 - INFO - Model saved
2024-10-08 15:48:43,313 - INFO - Validation loss: 9.891966247558594
2024-10-08 15:48:43,352 - INFO - Sample 1: Hello, I am a language model,,, in, the.
 unhappy delightful never, the the;ator
, of, and. the,.
2024-10-08 15:48:43,352 - INFO - Sample 2: Hello, I am a language model, the (,,., of don,. certificates ( the
. and the., theaddon of the.
2024-10-08 15:48:43,352 - INFO - Sample 3: Hello, I am a language model, the the hipp. neverEGIN the the,imated the, that and of the the,. the the the,,
2024-10-08 15:48:43,352 - INFO - Sample 4: Hello, I am a language model,. it, of,, the.. Nielsen,,, the,. vehicle a
 the;..Statistics
2024-10-08 15:48:43,352 - INFO - Sample 5: Hello, I am a language model,
 and the;,..ator,, Hilton,,,�,.. the. the.addon,
2024-10-08 15:48:48,644 - INFO - tokens per second = 75395 | loss: 9.128587 | gradient norm 0.0665 | dt 6953.889370 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:53,554 - INFO - tokens per second = 106765 | loss: 9.119568 | gradient norm 0.0714 | dt 4910.656929 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:48:58,570 - INFO - tokens per second = 104540 | loss: 9.084222 | gradient norm 0.0704 | dt 5015.213251 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:03,476 - INFO - tokens per second = 106858 | loss: 9.043745 | gradient norm 0.0701 | dt 4906.394482 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:03,476 - INFO - Saving model
2024-10-08 15:49:03,976 - INFO - Model saved
2024-10-08 15:49:05,035 - INFO - Validation loss: 9.804733276367188
2024-10-08 15:49:05,075 - INFO - Sample 1: Hello, I am a language model, the the in the,.
 is an� the,,.ator
 the and, to., the.
2024-10-08 15:49:05,075 - INFO - Sample 2: Hello, I am a language model,.addon,, the, of go,. go Ke,
 the and the. a the it of the.
2024-10-08 15:49:05,075 - INFO - Sample 3: Hello, I am a language model,,,addon. neverEGIN. the,imated.. in and of the the.. the the the,,
2024-10-08 15:49:05,075 - INFO - Sample 4: Hello, I am a language model,.addon, of the the,.. hipp the the., a. ratified to
, (..addon
2024-10-08 15:49:05,075 - INFO - Sample 5: Hello, I am a language model,
 and the., to. don the,ーテ,,, certificates,. the the. the.�.
2024-10-08 15:49:15,153 - INFO - tokens per second = 44900 | loss: 9.055830 | gradient norm 0.0689 | dt 11676.855564 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:19,879 - INFO - tokens per second = 110935 | loss: 9.032126 | gradient norm 0.0654 | dt 4726.097345 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:24,609 - INFO - tokens per second = 110836 | loss: 8.988195 | gradient norm 0.0773 | dt 4730.283976 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:29,474 - INFO - tokens per second = 107785 | loss: 8.935763 | gradient norm 0.0672 | dt 4864.185095 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:49:29,474 - INFO - Saving model
2024-10-08 15:49:30,007 - INFO - Model saved
2024-10-08 15:49:31,168 - INFO - Validation loss: 9.703260803222657
2024-10-08 15:49:31,208 - INFO - Sample 1: Hello, I am a language model,.. that.,. and.addon don.,, by18 and. of, to the,. and
2024-10-08 15:49:31,208 - INFO - Sample 2: Hello, I am a language model,,�.. the.
Statistics. theen by, of the of, the a,),
. of
2024-10-08 15:49:31,208 - INFO - Sample 3: Hello, I am a language model,,. go
. it,,,-,, in and and,,.,,,,.,
2024-10-08 15:49:31,208 - INFO - Sample 4: Hello, I am a language model,,,. of.., the the theater...,. the vehicle to and,.. the don
2024-10-08 15:49:31,208 - INFO - Sample 5: Hello, I am a language model, of of,-. to, read,,en... can. a the,., the by.
2024-10-08 15:49:36,609 - INFO - tokens per second = 73467 | loss: 8.934229 | gradient norm 0.0628 | dt 7136.336088 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:49:41,378 - INFO - tokens per second = 109978 | loss: 8.939977 | gradient norm 0.0610 | dt 4767.209768 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:49:46,175 - INFO - tokens per second = 109267 | loss: 8.922780 | gradient norm 0.0607 | dt 4798.233032 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:49:51,094 - INFO - tokens per second = 106586 | loss: 8.860882 | gradient norm 0.0701 | dt 4918.935299 ms | CUDA memory: 2003.26 MB | CPU memory: 2.24 GB
2024-10-08 15:49:51,094 - INFO - Saving model
2024-10-08 15:49:51,621 - INFO - Model saved
2024-10-08 15:49:52,704 - INFO - Validation loss: 9.591786193847657
2024-10-08 15:49:52,745 - INFO - Sample 1: Hello, I am a language model,,, is,.. and, read if,.. If; and, of. to the., and
2024-10-08 15:49:52,746 - INFO - Sample 2: Hello, I am a language model,.imated..
. theEGIN, theen by, and the of, the a.),
, the
2024-10-08 15:49:52,746 - INFO - Sample 3: Hello, I am a language model,.. if
. it,.. (,. in of of,,.,,,,.,
2024-10-08 15:49:52,746 - INFO - Sample 4: Hello, I am a language model,.imated.
.., the the Australia..,, a theator to and. the the the don
2024-10-08 15:49:52,746 - INFO - Sample 5: Hello, I am a language model, and of. as, to the Ke., benefits,,, read, the the. the. the),,
2024-10-08 15:49:57,933 - INFO - tokens per second = 76665 | loss: 8.867895 | gradient norm 0.0619 | dt 6838.722467 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:02,801 - INFO - tokens per second = 107685 | loss: 8.821939 | gradient norm 0.0638 | dt 4868.712187 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:07,695 - INFO - tokens per second = 107141 | loss: 8.782354 | gradient norm 0.0662 | dt 4893.424273 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:12,563 - INFO - tokens per second = 107697 | loss: 8.765656 | gradient norm 0.0628 | dt 4868.185759 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:12,563 - INFO - Saving model
2024-10-08 15:50:13,072 - INFO - Model saved
2024-10-08 15:50:14,146 - INFO - Validation loss: 9.47681884765625
2024-10-08 15:50:14,185 - INFO - Sample 1: Hello, I am a language model, the the that the,. and is from can the,, If Ke and the
, to., the and
2024-10-08 15:50:14,185 - INFO - Sample 2: Hello, I am a language model,, never,,., the 15,. benefits never the and. of,. a the by of the.
2024-10-08 15:50:14,185 - INFO - Sample 3: Hello, I am a language model,,,�., it the the,- the the in
 of the the,, the the the,,
2024-10-08 15:50:14,185 - INFO - Sample 4: Hello, I am a language model,, never, and,, the.. 15,,, the a. from to and the,..;
2024-10-08 15:50:14,185 - INFO - Sample 5: Hello, I am a language model, and and,-, to.�,, post,,, Ke,.. the. the. can,
2024-10-08 15:50:19,477 - INFO - tokens per second = 75829 | loss: 8.753209 | gradient norm 0.0589 | dt 6914.105415 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:24,424 - INFO - tokens per second = 105976 | loss: 8.707340 | gradient norm 0.0597 | dt 4947.231054 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:29,152 - INFO - tokens per second = 110898 | loss: 8.689613 | gradient norm 0.0609 | dt 4727.662802 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:34,106 - INFO - tokens per second = 105819 | loss: 8.633508 | gradient norm 0.0627 | dt 4954.557896 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:34,107 - INFO - Saving model
2024-10-08 15:50:34,618 - INFO - Model saved
2024-10-08 15:50:35,680 - INFO - Validation loss: 9.349431610107422
2024-10-08 15:50:35,718 - INFO - Sample 1: Hello, I am a language model,,, in,. the
 is are never, the the If don
, and the a. a,.
2024-10-08 15:50:35,719 - INFO - Sample 2: Hello, I am a language model,. go,, the, of Australia,. not never. and. of the. to the), of the.
2024-10-08 15:50:35,719 - INFO - Sample 3: Hello, I am a language model, the, from of the it the to,- the, that and and,, the.,,, the the
2024-10-08 15:50:35,719 - INFO - Sample 4: Hello, I am a language model,.
, and,,. the the which,,,. to. Ke a
. of. the never
2024-10-08 15:50:35,719 - INFO - Sample 5: Hello, I am a language model,
 and the-, a the�,, Ke,,, and,. the the.. the an,
2024-10-08 15:50:40,864 - INFO - tokens per second = 77582 | loss: 8.657407 | gradient norm 0.0578 | dt 6757.825851 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
2024-10-08 15:50:45,640 - INFO - tokens per second = 109805 | loss: 8.597836 | gradient norm 0.0612 | dt 4774.734974 ms | CUDA memory: 2003.26 MB | CPU memory: 2.25 GB
Traceback (most recent call last):
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 294, in <module>
    loss, norm = training_step(x, y)
                 ^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/Documents/gpt2/gpt2_fabric.py", line 265, in training_step
    norm = torch.nn.utils.clip_grad_norm_(model.parameters(),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 21, in _no_grad_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py", line 82, in clip_grad_norm_
    clip_coef = max_norm / (total_norm + 1e-6)
                ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~
  File "/home/enzo/mambaforge/envs/up_to_date/lib/python3.12/site-packages/torch/_tensor.py", line 35, in wrapped
    @functools.wraps(f, assigned=assigned)

KeyboardInterrupt
